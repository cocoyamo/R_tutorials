[["index.html", "Hello and welcome to our RStudio journey! Chapter 1 Introduction", " Hello and welcome to our RStudio journey! Moya 2024-10-13 Chapter 1 Introduction Hi there! I‚Äôm a student (though not for much longer) who has had a love-hate relationship with RStudio. It‚Äôs been a journey of both struggle and excitement. I frequently use statistical analyses like t-tests, ANOVAs, and linear regressions. I‚Äôm also passionate about creating graphs in RStudio. That‚Äôs why I‚Äôve decided to document my journey here‚Äîit‚Äôll save me from digging through old files to copy code whenever I need to perform a new analysis. Occasionally, I use RStudio for amusing projects, such as creating national flags, just for fun. You‚Äôll likely see some of these creative endeavors here. Feel free to leave comments or suggestions. I‚Äôm still a beginner in the fascinating world of R and am eager to learn new things! Best, Moya Reykjavik, 2024 "],["rstudio-environment-and-installation.html", "Chapter 2 RStudio Environment and Installation", " Chapter 2 RStudio Environment and Installation first thing first: install and library I wish someone had used this analogy when I was learning R Studio for the very first time. People are constantly saying ‚ÄúOh you need to install this package‚Äù, and therefore I install every package every time I use R Studio. Then people will ask you to ‚Äúcall the package out‚Äù using a ‚Äòlibrary‚Äô function. These two things inside R Studio confused me a lot in the beginning, (and I was mocked by a TA who was very inconsiderate of people who have never learned coding before), hopefully here you can find some answers. And I will not mock you. I swear. I know the struggles. I now think of this as making a sandwich. Pick whatever sandwich you like. I will do a peanut butter and chocolate sandwich here. So, imagine you will make a peanut butter and chocolate sandwich. You need ingredients. So you went to a nearby grocery store to purchase chocolate spread, peanut butter, and toast. (Feel free to switch to any other food you like, also please do not follow my recipe if you are allergic to peanuts or chocolate!) This step (getting ingredients from a store) is called install. Then, you go back to your kitchen and pull these ingredients out from your reusable bag, this action is similar to the library function. Let‚Äôs assume these ingredients will never run out. (What a heaven!) Then, the next time you want the peanut butter and chocolate sandwich, all you need to do is pull out these ingredients again. There is no need to go back to the store every time you want it, you already have it in your kitchen! Therefore, whenever you need to use some package you have not used before, you need to install them first. Then afterward, the only thing you need to do is to use the library function to pull this magical stuff out of your bag. Okay, I hope you are still with me, and not already in the kitchen looking for your chocolate spread. "],["data-import-and-reading.html", "Chapter 3 Data Import and Reading 3.1 Import Your Data 3.2 Dataset packages 3.3 Ways to Check Data", " Chapter 3 Data Import and Reading Let‚Äôs import our data! 3.1 Import Your Data Note: If this is your first time import data and your data is from an Excel file, remember to type install.packages(\"readxl\") in your coding space first. install.packages(&quot;readxl&quot;) library(readxl) There are, of course, tons of ways to import your data, but the following is what I use most often. I click ‚ÄúImport Dataset‚Äù in the top-right corner of the Environment box. Then choose ‚ÄúImport‚Äù, select ‚ÄúFrom Excel‚Äù (or ‚ÄúFrom Text‚Äù if I have a .csv file), and use ‚ÄúBrowse‚Äù in the top-right corner to pick the file I want to import. You can either double-click the file or click it once and then click the ‚ÄúOpen‚Äù at the bottom-right. The middle part is the Data Preview section, where you can see your data. Don‚Äôt import the wrong file! (I‚Äôve done that multiple times, especially when I‚Äôm lazy about giving files proper names üòÖ) Next, in the bottom-right corner, you‚Äôll see a section called Code Preview. The code may look something like this (but not identical, because, hopefully, we‚Äôre using different file names). library(readxl) weather_math &lt;- read_excel(&quot;~/Documents/R_tutorials/example files/weather_math.xlsx&quot;) View(weather_math) Now you‚Äôve seen the Code Preview section, at the end of it, there‚Äôs a tiny icon that looks like a clipboard. What do you do? CLICK IT! Great Job!! Now you‚Äôve copied the code necessary to import your file. Press Import in the bottom-right. Go back to the coding section. Paste it (Ctrl/Command + v) into the coding section (the top-left section of the interface). (Let‚Äôs hope RStudio never change their default interface or I‚Äôll have to rewrite this part.üòÖ) Also, you can sometimes use head() to see the first few rows of your data, just to make sure everything was imported correctly. head(weather_math) ## # A tibble: 6 √ó 3 ## id day score ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 sunny 9 ## 2 2 sunny 8 ## 3 3 sunny 7 ## 4 4 sunny 8 ## 5 5 sunny 8 ## 6 6 sunny 8 Or you could just type in the data‚Äôs name. weather_math ## # A tibble: 20 √ó 3 ## id day score ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 sunny 9 ## 2 2 sunny 8 ## 3 3 sunny 7 ## 4 4 sunny 8 ## 5 5 sunny 8 ## 6 6 sunny 8 ## 7 7 sunny 6 ## 8 8 sunny 5 ## 9 9 sunny 3 ## 10 10 sunny 4 ## 11 1 rainy 1 ## 12 2 rainy 3 ## 13 3 rainy 5 ## 14 4 rainy 7 ## 15 5 rainy 6 ## 16 6 rainy 5 ## 17 7 rainy 6 ## 18 8 rainy 7 ## 19 9 rainy 5 ## 20 10 rainy 3 3.1.1 Weather Math Data Explanation Let‚Äôs take a peek at this data, so you‚Äôll have a better grasp of our future examples. weather_math ## # A tibble: 20 √ó 3 ## id day score ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 sunny 9 ## 2 2 sunny 8 ## 3 3 sunny 7 ## 4 4 sunny 8 ## 5 5 sunny 8 ## 6 6 sunny 8 ## 7 7 sunny 6 ## 8 8 sunny 5 ## 9 9 sunny 3 ## 10 10 sunny 4 ## 11 1 rainy 1 ## 12 2 rainy 3 ## 13 3 rainy 5 ## 14 4 rainy 7 ## 15 5 rainy 6 ## 16 6 rainy 5 ## 17 7 rainy 6 ## 18 8 rainy 7 ## 19 9 rainy 5 ## 20 10 rainy 3 This is a made-up data. Ten imaginary people participated in this imaginary research. They took a math test on both a rainy day and a sunny day, and their scores were recorded. The first column represents the participant number, the second column shows the weather (either sunny or rainy), and the third column contains their scores. 3.2 Dataset packages 3.2.1 babynames There are various data packages available in R, and we can easily access them by installing the appropriate package. For example, we can install a package called babynames . This package contains baby names in the US from the year 1880 to year 2017. Let‚Äôs take a look. install.packages(&quot;babynames&quot;) library(babynames) babynames ## # A tibble: 1,924,665 √ó 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1880 F Mary 7065 0.0724 ## 2 1880 F Anna 2604 0.0267 ## 3 1880 F Emma 2003 0.0205 ## 4 1880 F Elizabeth 1939 0.0199 ## 5 1880 F Minnie 1746 0.0179 ## 6 1880 F Margaret 1578 0.0162 ## 7 1880 F Ida 1472 0.0151 ## 8 1880 F Alice 1414 0.0145 ## 9 1880 F Bertha 1320 0.0135 ## 10 1880 F Sarah 1288 0.0132 ## # ‚Ñπ 1,924,655 more rows RStudio creates a separate page for the data when we use View(). We can see that there are 5 columns: year, sex, name, n, and prop. Wait, what is prop? When we encounter questions like this, we can type ?dataset or ?function on the Console. In this case, we typed ?babynames. After hitting enter, the Help screen on the right side will display some information. Upon reading the explanation of this dataset, we learn that prop refers to n divided by the total number of babies of that sex with that name born in that year. 3.2.2 starwars There are also built-in datasets within the dplyr package. For example, there is a dataset called starwars. We can import it with just a few lines of code, simply by calling the dplyr package where starwars dataset is stored. install.packages(&quot;dplyr&quot;) library(dplyr) starwars ## # A tibble: 87 √ó 14 ## name height mass hair_color skin_color eye_color birth_year ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Luke Sky‚Ä¶ 172 77 blond fair blue 19 ## 2 C-3PO 167 75 &lt;NA&gt; gold yellow 112 ## 3 R2-D2 96 32 &lt;NA&gt; white, bl‚Ä¶ red 33 ## 4 Darth Va‚Ä¶ 202 136 none white yellow 41.9 ## 5 Leia Org‚Ä¶ 150 49 brown light brown 19 ## 6 Owen Lars 178 120 brown, gr‚Ä¶ light blue 52 ## 7 Beru Whi‚Ä¶ 165 75 brown light blue 47 ## 8 R5-D4 97 32 &lt;NA&gt; white, red red NA ## 9 Biggs Da‚Ä¶ 183 84 black light brown 24 ## 10 Obi-Wan ‚Ä¶ 182 77 auburn, w‚Ä¶ fair blue-gray 57 ## # ‚Ñπ 77 more rows ## # ‚Ñπ 7 more variables: sex &lt;chr&gt;, gender &lt;chr&gt;, homeworld &lt;chr&gt;, ## # species &lt;chr&gt;, films &lt;list&gt;, vehicles &lt;list&gt;, starships &lt;list&gt; 3.3 Ways to Check Data These functions are commonly used for inspecting datasets. View() opens a new page to display the datasets. glimpse(), head(), tail(), dim(), and slice() provide different ways to explore data. You can also check the dimensions of your datasets using ncol() and nrow(). Both can be displayed at once by using dim(). "],["overview-of-tidyverse-and-core-functions.html", "Chapter 4 Overview of Tidyverse and Core Functions 4.1 pipe example", " Chapter 4 Overview of Tidyverse and Core Functions I really love tidyverse. It‚Äôs a game changer. The three packages I use most often from tidyverse are: ggplot2 dplyr tidyr But first, let‚Äôs clarify what tidyverse is. Tidyverse is a collection of packages that makes data transformation and visualization (and therefore, my life) easier. Under the tidyverse umbrella, we can handle data like pros. We‚Äôll dive into ggplot2 in a later chapter. For now, let‚Äôs focus on dplyr and tidyr first. If you haven‚Äôt use tidyverse before, you need to install the package first. install.packages(&quot;tidyverse&quot;) install.packages(&quot;dplyr&quot;) install.packages(&quot;tidyr&quot;) Next, don‚Äôt forget to load your packages uding the library() function. library(&quot;tidyverse&quot;) library(&quot;dplyr&quot;) library(&quot;tidyr&quot;) Now, you‚Äôre all set. Before jumping into the functions, let‚Äôs meet a funny-looking friend: The pipe (%&gt;% / |&gt;). They look like this: %&gt;% |&gt; In my humble opinion, this is one of the greatest analogies of this century. Although it doesn‚Äôt look like a real pipe, it functions like one. Let‚Äôs use an example to see how it works. 4.1 pipe example We use the babynames package mentioned above to demonstrate the use of the pipe. We can take a look at the data again. babynames ## # A tibble: 1,924,665 √ó 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1880 F Mary 7065 0.0724 ## 2 1880 F Anna 2604 0.0267 ## 3 1880 F Emma 2003 0.0205 ## 4 1880 F Elizabeth 1939 0.0199 ## 5 1880 F Minnie 1746 0.0179 ## 6 1880 F Margaret 1578 0.0162 ## 7 1880 F Ida 1472 0.0151 ## 8 1880 F Alice 1414 0.0145 ## 9 1880 F Bertha 1320 0.0135 ## 10 1880 F Sarah 1288 0.0132 ## # ‚Ñπ 1,924,655 more rows Now, let‚Äôs say we want to see the names of babies born in the year 2000. babynames %&gt;% filter(year == 2000) ## # A tibble: 29,769 √ó 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2000 F Emily 25953 0.0130 ## 2 2000 F Hannah 23080 0.0116 ## 3 2000 F Madison 19967 0.0100 ## 4 2000 F Ashley 17997 0.00902 ## 5 2000 F Sarah 17697 0.00887 ## 6 2000 F Alexis 17629 0.00884 ## 7 2000 F Samantha 17266 0.00866 ## 8 2000 F Jessica 15709 0.00787 ## 9 2000 F Elizabeth 15094 0.00757 ## 10 2000 F Taylor 15078 0.00756 ## # ‚Ñπ 29,759 more rows Here you‚Äôll see all the baby names from 2000! In the code, I used the pipe (%&gt;%) to direct my dataset (babynames) into the next function, filter(). Inside the filter() function, I specified that I wanted to see only babies born in the year 2000. In other words, I filtered out all the rows in the year column except those with the value ‚Äò2000‚Äô. The great thing about the pipe (%&gt;% / |&gt;) is that you can chain multiple operations together. Just like water flows from east to west, you can direct your data from one operation to the next. Let‚Äôs try it out. babynames %&gt;% filter(year == 2000) %&gt;% filter(sex == &quot;F&quot;) ## # A tibble: 17,653 √ó 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2000 F Emily 25953 0.0130 ## 2 2000 F Hannah 23080 0.0116 ## 3 2000 F Madison 19967 0.0100 ## 4 2000 F Ashley 17997 0.00902 ## 5 2000 F Sarah 17697 0.00887 ## 6 2000 F Alexis 17629 0.00884 ## 7 2000 F Samantha 17266 0.00866 ## 8 2000 F Jessica 15709 0.00787 ## 9 2000 F Elizabeth 15094 0.00757 ## 10 2000 F Taylor 15078 0.00756 ## # ‚Ñπ 17,643 more rows Here, we added \"F\" inside quotes because it‚Äôs a character, not a number. We need to specify this so that RStudio can understands what we mean. Now, the data is shows female babies born in year 2000. We can also achieve this result in another way. babynames %&gt;% filter(year == 2000 &amp; sex == &quot;F&quot;) ## # A tibble: 17,653 √ó 5 ## year sex name n prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2000 F Emily 25953 0.0130 ## 2 2000 F Hannah 23080 0.0116 ## 3 2000 F Madison 19967 0.0100 ## 4 2000 F Ashley 17997 0.00902 ## 5 2000 F Sarah 17697 0.00887 ## 6 2000 F Alexis 17629 0.00884 ## 7 2000 F Samantha 17266 0.00866 ## 8 2000 F Jessica 15709 0.00787 ## 9 2000 F Elizabeth 15094 0.00757 ## 10 2000 F Taylor 15078 0.00756 ## # ‚Ñπ 17,643 more rows Let‚Äôs explore more data transformations in the next chapter. "],["data-cleaning-and-transformation.html", "Chapter 5 Data Cleaning and Transformation", " Chapter 5 Data Cleaning and Transformation Here is a dataset for superheros that I downloaded from here. library(readr) setwd (&quot;~/Documents/R_tutorials&quot;) heroes &lt;- read_delim(&quot;example files/heroes.csv&quot;, delim = &quot;;&quot;, escape_double = FALSE, trim_ws = TRUE) View(heroes) Note that the spreadsheet is in .csv format. Therefore, when importing data, we should choose From Text(readr) instead of From Text(Excel). However, as you may notice from the Preview, the data is not ideal ‚Äì it appears as a single row, with all the information packed into one. To resolve this, we can click on Delimiter and select Semicolon, telling RStudio that the columns in this dataset are separated by semicolons (;) rather than commas or tabs. Once the data is properly imported, we can see that it contains information about many superheroes. If we want a clearer view to focus on the data that we need for analysis, we can use select() function to choose specific columns. heroes |&gt; select(c(&quot;Name&quot;, &quot;Height&quot;, &quot;Weight&quot;, &quot;Gender&quot;, &quot;Eye color&quot;, &quot;Hair color&quot;, &quot;Strength&quot;, &quot;Intelligence&quot;)) ## # A tibble: 735 √ó 8 ## Name Height Weight Gender `Eye color` `Hair color` Strength ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 A-Bomb 203. 442. M Yellow No Hair 100 ## 2 Abraxas NA NA M Blue Black 100 ## 3 Abominati‚Ä¶ 203. 442. M Green No Hair 80 ## 4 Adam Monr‚Ä¶ NA NA M Blue Blond 10 ## 5 Agent 13 173. 61.0 F Blue Blond NA ## 6 Air-Walker 189. 108. M Blue White 85 ## 7 Agent Bob 178. 81.4 M Brown Brown 10 ## 8 Abe Sapien 191. 65.4 M Blue No Hair 30 ## 9 Abin Sur 186. 90.9 M Blue No Hair 90 ## 10 Angela NA NA F &lt;NA&gt; &lt;NA&gt; 100 ## # ‚Ñπ 725 more rows ## # ‚Ñπ 1 more variable: Intelligence &lt;chr&gt; Now, if we want to filter for superheroes with high intelligence, we can use the filter() function. This function allows us to extract rows that meet specified conditions. heroes |&gt; filter(Intelligence == &quot;high&quot;) ## # A tibble: 144 √ó 12 ## Name Identity `Birth place` Publisher Height Weight Gender ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Abraxas Abraxas Within Etern‚Ä¶ Marvel C‚Ä¶ NA NA M ## 2 Abe Sapien Abraham‚Ä¶ &lt;NA&gt; Dark Hor‚Ä¶ 191. 65.4 M ## 3 Angela &lt;NA&gt; &lt;NA&gt; Image Co‚Ä¶ NA NA F ## 4 Yoda Yoda &lt;NA&gt; George L‚Ä¶ 66.3 17.0 M ## 5 Zatanna Zatanna‚Ä¶ &lt;NA&gt; DC Comics 170. 57.8 F ## 6 Yellowjack‚Ä¶ Hank Pym Elmsford, Ne‚Ä¶ Marvel C‚Ä¶ 183. 83.7 M ## 7 X-Man Nate Gr‚Ä¶ American Nor‚Ä¶ Marvel C‚Ä¶ 176. 61.8 M ## 8 Wonder Wom‚Ä¶ Diana P‚Ä¶ Themyscira DC Comics 183. 74.7 F ## 9 Watcher Uatu &lt;NA&gt; Marvel C‚Ä¶ NA NA M ## 10 Warlock Adam Wa‚Ä¶ The Beehive,‚Ä¶ Marvel C‚Ä¶ 188. 108. M ## # ‚Ñπ 134 more rows ## # ‚Ñπ 5 more variables: `First appearance` &lt;dbl&gt;, `Eye color` &lt;chr&gt;, ## # `Hair color` &lt;chr&gt;, Strength &lt;dbl&gt;, Intelligence &lt;chr&gt; In fact, select() and filter() can be combined. Let‚Äôs look for female superheroes with strength over 50 and high intelligence levels. heroes |&gt; select(c(&quot;Name&quot;, &quot;Gender&quot;, &quot;Strength&quot;, &quot;Intelligence&quot;)) |&gt; filter(Gender == &quot;F&quot; &amp; Strength &gt;= 50 &amp; Intelligence == &quot;high&quot;) ## # A tibble: 18 √ó 4 ## Name Gender Strength Intelligence ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Angela F 100 high ## 2 Wonder Woman F 100 high ## 3 Valkyrie F 95 high ## 4 Supergirl F 100 high ## 5 Silk Spectre II F 55 high ## 6 She-Hulk F 100 high ## 7 Power Girl F 100 high ## 8 Phoenix F 100 high ## 9 Lady Bullseye F 75 high ## 10 Jean Grey F 80 high ## 11 Granny Goodness F 100 high ## 12 Giganta F 90 high ## 13 Faora F 95 high ## 14 Donna Troy F 95 high ## 15 Cheetah III F 100 high ## 16 Cat F 90 high ## 17 Captain Marvel F 90 high ## 18 Big Barda F 100 high If we want to adjust this filter to include superheroes with either good or high intelligence, there are two ways to do it. The first method is to use the | operator (which means ‚Äúor‚Äù). The second method is to use the %in% operator, which selects data that fits either of the specified conditions. # method 1 heroes |&gt; select(c(&quot;Name&quot;, &quot;Gender&quot;, &quot;Strength&quot;, &quot;Intelligence&quot;)) |&gt; filter(Gender == &quot;F&quot; &amp; Strength &gt;= 50) |&gt; filter(Intelligence == &quot;high&quot; | Intelligence == &quot;good&quot;) ## # A tibble: 47 √ó 4 ## Name Gender Strength Intelligence ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Angela F 100 high ## 2 Wonder Girl F 90 good ## 3 Wonder Woman F 100 high ## 4 Valkyrie F 95 high ## 5 Vindicator F 65 good ## 6 Thor Girl F 85 good ## 7 T-X F 65 good ## 8 Supergirl F 100 high ## 9 Stargirl F 80 good ## 10 Spider-Gwen F 55 good ## # ‚Ñπ 37 more rows # method 2 heroes |&gt; select(c(&quot;Name&quot;, &quot;Gender&quot;, &quot;Strength&quot;, &quot;Intelligence&quot;)) |&gt; filter(Gender == &quot;F&quot; &amp; Strength &gt;= 50) |&gt; filter(Intelligence %in% c(&quot;high&quot;, &quot;good&quot;)) ## # A tibble: 47 √ó 4 ## Name Gender Strength Intelligence ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Angela F 100 high ## 2 Wonder Girl F 90 good ## 3 Wonder Woman F 100 high ## 4 Valkyrie F 95 high ## 5 Vindicator F 65 good ## 6 Thor Girl F 85 good ## 7 T-X F 65 good ## 8 Supergirl F 100 high ## 9 Stargirl F 80 good ## 10 Spider-Gwen F 55 good ## # ‚Ñπ 37 more rows Both methods give us the same result. While the first method is more straightforward, I personally feel cooler using the second oneüòé. Now, let‚Äôs calculate the superheroes‚Äô Body Mass Index (BMI). The formula is: \\[ BMI = weight(kg)/height(m)^2 \\] So, we need to : Add a new column that converts height from centimeters to meters. Square the height in meters. Divide weight by the square of the height. heroes |&gt; mutate(Height_m = Height / 100) |&gt; # convert heights from cm to m mutate(Height_m2 = Height_m*Height_m) |&gt; # square of the heights mutate(BMI = Weight / Height_m2) # divide weights by the squrare of the heights ## # A tibble: 735 √ó 15 ## Name Identity `Birth place` Publisher Height Weight Gender ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 A-Bomb Richard‚Ä¶ Scarsdale, A‚Ä¶ Marvel C‚Ä¶ 203. 442. M ## 2 Abraxas Abraxas Within Etern‚Ä¶ Marvel C‚Ä¶ NA NA M ## 3 Abomination Emil Bl‚Ä¶ Zagreb, Yugo‚Ä¶ Marvel C‚Ä¶ 203. 442. M ## 4 Adam Monroe &lt;NA&gt; &lt;NA&gt; NBC - He‚Ä¶ NA NA M ## 5 Agent 13 Sharon ‚Ä¶ &lt;NA&gt; Marvel C‚Ä¶ 173. 61.0 F ## 6 Air-Walker Gabriel‚Ä¶ Xandar, a pl‚Ä¶ Marvel C‚Ä¶ 189. 108. M ## 7 Agent Bob Bob &lt;NA&gt; Marvel C‚Ä¶ 178. 81.4 M ## 8 Abe Sapien Abraham‚Ä¶ &lt;NA&gt; Dark Hor‚Ä¶ 191. 65.4 M ## 9 Abin Sur &lt;NA&gt; Ungara DC Comics 186. 90.9 M ## 10 Angela &lt;NA&gt; &lt;NA&gt; Image Co‚Ä¶ NA NA F ## # ‚Ñπ 725 more rows ## # ‚Ñπ 8 more variables: `First appearance` &lt;dbl&gt;, `Eye color` &lt;chr&gt;, ## # `Hair color` &lt;chr&gt;, Strength &lt;dbl&gt;, Intelligence &lt;chr&gt;, ## # Height_m &lt;dbl&gt;, Height_m2 &lt;dbl&gt;, BMI &lt;dbl&gt; We can either break this down into multiple steps or, for simplicity, combine everything into one line of code. heroes |&gt; mutate(BMI = Weight / (Height/100)^2) ## # A tibble: 735 √ó 13 ## Name Identity `Birth place` Publisher Height Weight Gender ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 A-Bomb Richard‚Ä¶ Scarsdale, A‚Ä¶ Marvel C‚Ä¶ 203. 442. M ## 2 Abraxas Abraxas Within Etern‚Ä¶ Marvel C‚Ä¶ NA NA M ## 3 Abomination Emil Bl‚Ä¶ Zagreb, Yugo‚Ä¶ Marvel C‚Ä¶ 203. 442. M ## 4 Adam Monroe &lt;NA&gt; &lt;NA&gt; NBC - He‚Ä¶ NA NA M ## 5 Agent 13 Sharon ‚Ä¶ &lt;NA&gt; Marvel C‚Ä¶ 173. 61.0 F ## 6 Air-Walker Gabriel‚Ä¶ Xandar, a pl‚Ä¶ Marvel C‚Ä¶ 189. 108. M ## 7 Agent Bob Bob &lt;NA&gt; Marvel C‚Ä¶ 178. 81.4 M ## 8 Abe Sapien Abraham‚Ä¶ &lt;NA&gt; Dark Hor‚Ä¶ 191. 65.4 M ## 9 Abin Sur &lt;NA&gt; Ungara DC Comics 186. 90.9 M ## 10 Angela &lt;NA&gt; &lt;NA&gt; Image Co‚Ä¶ NA NA F ## # ‚Ñπ 725 more rows ## # ‚Ñπ 6 more variables: `First appearance` &lt;dbl&gt;, `Eye color` &lt;chr&gt;, ## # `Hair color` &lt;chr&gt;, Strength &lt;dbl&gt;, Intelligence &lt;chr&gt;, ## # BMI &lt;dbl&gt; Either approach will give the same result, so you can shoose whichever suits you best. Tip: By default, new columns appear on the right, but if you prefer them on the left (to make it easier to check when there are many columns), you can specify .after = \"column_name\" in mutate() to position the new column immediately after a chosen column. heroes |&gt; mutate(BMI = Weight / (Height/100)^2, .before = 1) ## # A tibble: 735 √ó 13 ## BMI Name Identity `Birth place` Publisher Height Weight Gender ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 107. A-Bo‚Ä¶ Richard‚Ä¶ Scarsdale, A‚Ä¶ Marvel C‚Ä¶ 203. 442. M ## 2 NA Abra‚Ä¶ Abraxas Within Etern‚Ä¶ Marvel C‚Ä¶ NA NA M ## 3 107. Abom‚Ä¶ Emil Bl‚Ä¶ Zagreb, Yugo‚Ä¶ Marvel C‚Ä¶ 203. 442. M ## 4 NA Adam‚Ä¶ &lt;NA&gt; &lt;NA&gt; NBC - He‚Ä¶ NA NA M ## 5 20.3 Agen‚Ä¶ Sharon ‚Ä¶ &lt;NA&gt; Marvel C‚Ä¶ 173. 61.0 F ## 6 30.4 Air-‚Ä¶ Gabriel‚Ä¶ Xandar, a pl‚Ä¶ Marvel C‚Ä¶ 189. 108. M ## 7 25.6 Agen‚Ä¶ Bob &lt;NA&gt; Marvel C‚Ä¶ 178. 81.4 M ## 8 17.9 Abe ‚Ä¶ Abraham‚Ä¶ &lt;NA&gt; Dark Hor‚Ä¶ 191. 65.4 M ## 9 26.4 Abin‚Ä¶ &lt;NA&gt; Ungara DC Comics 186. 90.9 M ## 10 NA Ange‚Ä¶ &lt;NA&gt; &lt;NA&gt; Image Co‚Ä¶ NA NA F ## # ‚Ñπ 725 more rows ## # ‚Ñπ 5 more variables: `First appearance` &lt;dbl&gt;, `Eye color` &lt;chr&gt;, ## # `Hair color` &lt;chr&gt;, Strength &lt;dbl&gt;, Intelligence &lt;chr&gt; If, for example, I want the new BMI column to appear immediately after the Name column, I can write .after = \"Name\" to achieve that. heroes |&gt; mutate(BMI = Weight / (Height/100)^2, .after = &quot;Name&quot;) ## # A tibble: 735 √ó 13 ## Name BMI Identity `Birth place` Publisher Height Weight Gender ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 A-Bo‚Ä¶ 107. Richard‚Ä¶ Scarsdale, A‚Ä¶ Marvel C‚Ä¶ 203. 442. M ## 2 Abra‚Ä¶ NA Abraxas Within Etern‚Ä¶ Marvel C‚Ä¶ NA NA M ## 3 Abom‚Ä¶ 107. Emil Bl‚Ä¶ Zagreb, Yugo‚Ä¶ Marvel C‚Ä¶ 203. 442. M ## 4 Adam‚Ä¶ NA &lt;NA&gt; &lt;NA&gt; NBC - He‚Ä¶ NA NA M ## 5 Agen‚Ä¶ 20.3 Sharon ‚Ä¶ &lt;NA&gt; Marvel C‚Ä¶ 173. 61.0 F ## 6 Air-‚Ä¶ 30.4 Gabriel‚Ä¶ Xandar, a pl‚Ä¶ Marvel C‚Ä¶ 189. 108. M ## 7 Agen‚Ä¶ 25.6 Bob &lt;NA&gt; Marvel C‚Ä¶ 178. 81.4 M ## 8 Abe ‚Ä¶ 17.9 Abraham‚Ä¶ &lt;NA&gt; Dark Hor‚Ä¶ 191. 65.4 M ## 9 Abin‚Ä¶ 26.4 &lt;NA&gt; Ungara DC Comics 186. 90.9 M ## 10 Ange‚Ä¶ NA &lt;NA&gt; &lt;NA&gt; Image Co‚Ä¶ NA NA F ## # ‚Ñπ 725 more rows ## # ‚Ñπ 5 more variables: `First appearance` &lt;dbl&gt;, `Eye color` &lt;chr&gt;, ## # `Hair color` &lt;chr&gt;, Strength &lt;dbl&gt;, Intelligence &lt;chr&gt; Tip: Instead of using select() to manually keep only the columns you‚Äôve used during mutate() process, you can use .keep = \"used\". This tells RStudio to retain only the columns involved in the mutation process. heroes |&gt; mutate(BMI = Weight / (Height/100)^2, .keep = &quot;used&quot;) ## # A tibble: 735 √ó 3 ## Height Weight BMI ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 203. 442. 107. ## 2 NA NA NA ## 3 203. 442. 107. ## 4 NA NA NA ## 5 173. 61.0 20.3 ## 6 189. 108. 30.4 ## 7 178. 81.4 25.6 ## 8 191. 65.4 17.9 ## 9 186. 90.9 26.4 ## 10 NA NA NA ## # ‚Ñπ 725 more rows Now, I want to reflect on a personal experience from elementary school. After annual health exams, students were categorized based on their BMI, and teachers would tell those who were categorized as ‚Äúoverweight‚Äù, ‚Äúobese‚Äù, or ‚Äúunderweight‚Äù to be cautious about their BMI. I‚Äôm not going to dive into the mental toll this caused me as a child who often got labeled ‚Äúoverweight‚Äù, but let‚Äôs use this as an example to categorize numerical data into groups in RStudio. According to Wikipedia, BMI categories are (simply) defined as follows: BMI Category &lt; 18.5 underweight (UW) 18.5 - 24.9 (inclusive) normal weight (NW) 25.0 - 29.9 (inclusive) overweight (OW) &gt;= 30 obese (OB) Now, let‚Äôs categorize the superheroes based on their BMI values. We will use mutate() to create a new column for their BMI category. heroes |&gt; mutate(BMI = Weight / (Height/100)^2, .after = &quot;Name&quot;) |&gt; mutate(BMI_status = case_when(BMI &lt; 18.5 ~ &quot;underweight&quot;, BMI &gt;= 18.5 &amp; BMI &lt;= 24.9 ~ &quot;normal_weight&quot;, BMI &gt;= 25 &amp; BMI &lt;= 29.9 ~ &quot;overweight&quot;, BMI &gt;= 30 ~ &quot;obese&quot;), .after = &quot;BMI&quot;) -&gt; heroes2 heroes2 |&gt; count(BMI_status) ## # A tibble: 5 √ó 2 ## BMI_status n ## &lt;chr&gt; &lt;int&gt; ## 1 normal_weight 201 ## 2 obese 127 ## 3 overweight 114 ## 4 underweight 41 ## 5 &lt;NA&gt; 252 Once this is done, we can see how many superheroes are categorized as obese. You may notice a row with &lt;NA&gt; values, which occurs when the data is incomplete. If we don‚Äôt want to include rows with missing BMI values in our analysis, we can remove them by using na.omit(). This makes further analysis much easier. heroes2 |&gt; na.omit() |&gt; count(BMI_status) ## # A tibble: 4 √ó 2 ## BMI_status n ## &lt;chr&gt; &lt;int&gt; ## 1 normal_weight 48 ## 2 obese 40 ## 3 overweight 40 ## 4 underweight 13 You can also update your dataset to exclude missing values. Here, I assigned the cleaner version of my data: heroes2. heroes2 |&gt; na.omit() -&gt; heroes2 If you want to further categorize the data, such as determining how many male and female superheroes are categorized as obese or underweight, you can do so by adding another column to the count() function. heroes2 |&gt; count(Gender, BMI_status) ## # A tibble: 8 √ó 3 ## Gender BMI_status n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 F normal_weight 26 ## 2 F obese 1 ## 3 F overweight 1 ## 4 F underweight 12 ## 5 M normal_weight 22 ## 6 M obese 39 ## 7 M overweight 39 ## 8 M underweight 1 Alternatively, you can use group_by(), which we will cover in a future chapters, to achieve the same result. heroes2 |&gt; group_by(Gender) |&gt; count(BMI_status) ## # A tibble: 8 √ó 3 ## # Groups: Gender [2] ## Gender BMI_status n ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 F normal_weight 26 ## 2 F obese 1 ## 3 F overweight 1 ## 4 F underweight 12 ## 5 M normal_weight 22 ## 6 M obese 39 ## 7 M overweight 39 ## 8 M underweight 1 Lastly, let‚Äôs discuss renaming columns. You don‚Äôt need to go back to the original .csv or .xlsx files to change column names! For example, if we want to change the Hair color column to Hair_color and Eye color colun to Eye_color, we can do this directly in RStudio using the colnames() function. rename()?? another way (add later) colnames(heroes2)[colnames(heroes2) == &quot;Hair color&quot;] &lt;- &quot;Hair_color&quot; colnames(heroes2)[colnames(heroes2) == &quot;Eye color&quot;] &lt;- &quot;Eye_color&quot; "],["data-wrangling-and-reshaping.html", "Chapter 6 Data Wrangling and Reshaping 6.1 pivot 6.2 join 6.3 bind", " Chapter 6 Data Wrangling and Reshaping 6.1 pivot Pivoting can seem abstract at first, but it‚Äôs incredibly useful when you have a wide data and need to conduct further analysis. RStudio often works best with data in a long format. Let‚Äôs start with an example: Name Height (cm) Age Lily 150 20 Mary 160 18 John 156 14 Steve 180 15 Amy 174 16 This is straightforward: new rows can be added as more people are recorded. But sometimes, you‚Äôll encounter wide data, such as: Name Eng_C1 Eng_C2 Eng_C3 Math_C1 Math_C2 Math_C3 Kelly 90 95 80 90 80 97 Liam 70 80 94 80 89 79 Henry 79 80 85 96 92 90 Here, students‚Äô scores in English and Math from Chapter 1 (C1) to Chapter 3 (C3) are spread across multiple columns. This wide format can be tricky for analysis, and pivoting the data into a long format is often more effective. 6.1.1 example: converting wide to long format Let‚Äôs first create a data first. performance_original &lt;- data.frame( Name = c(&quot;Kelly&quot;, &quot;Liam&quot;, &quot;Henry&quot;, &quot;Alice&quot;, &quot;Jake&quot;, &quot;Dan&quot;), Eng_C1 = c(90, 70, 79, 98, 81, 79), Eng_C2 = c(95, 80, 80, 93, 93, 70), Eng_C3 = c(80, 94, 85, 89, 73, 91), Math_C1 = c(90, 80, 96, 83, 92, 68), Math_C2 = c(80, 89, 92, 72, 84, 83), Math_C3 = c(97, 79, 90, 74, 70, 92)) performance_original ## Name Eng_C1 Eng_C2 Eng_C3 Math_C1 Math_C2 Math_C3 ## 1 Kelly 90 95 80 90 80 97 ## 2 Liam 70 80 94 80 89 79 ## 3 Henry 79 80 85 96 92 90 ## 4 Alice 98 93 89 83 72 74 ## 5 Jake 81 93 73 92 84 70 ## 6 Dan 79 70 91 68 83 92 To convert this data into a long format, where each row represents one exam score, we can use pivot_longer(). The goal is to get data that looks like this: Name Subject Score Kelly Eng_C1 90 Kelly Eng_C2 95 Kelly Eng_C3 80 Kelly Math_C1 90 Kelly Math_C2 80 Kelly Math_C3 97 Liam Eng_C1 70 Liam Eng_C2 80 Liam Eng_C3 94 Liam Math_C1 80 Liam Math_C2 89 Liam Math_C3 79 Henry Eng_C1 79 Henry Eng_C2 80 ‚Ä¶ and so on Here‚Äôs the code to achieve that: performance_original |&gt; pivot_longer(!Name, names_to = &quot;Subject&quot;, values_to = &quot;Score&quot;) ## # A tibble: 36 √ó 3 ## Name Subject Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Kelly Eng_C1 90 ## 2 Kelly Eng_C2 95 ## 3 Kelly Eng_C3 80 ## 4 Kelly Math_C1 90 ## 5 Kelly Math_C2 80 ## 6 Kelly Math_C3 97 ## 7 Liam Eng_C1 70 ## 8 Liam Eng_C2 80 ## 9 Liam Eng_C3 94 ## 10 Liam Math_C1 80 ## # ‚Ñπ 26 more rows We can see that the data format is now what we intended. Let‚Äôs break down the key parts of the code used: !Name: The ! symbol tells RStudio to exclude the Name column from the pivot operation, meaning that we still want to keep the Name column intact in the dataset. names_to = \"Subject\": This argument specifies that we want to gather the multiple collumn names (e.g., Eng_C1, Math_C1, etc.) into a new column called Subject. values_to = \"Score\": This indicates that the values from the original columns (the actual exam scores) should be placed into a new column named Score. These two arguments (names_to and values_to) allow us to compress multiple columns into one, transforming the data from a wide to a long format. There are other ways to achieve the same result. The approach we used works well when the dataset doesn‚Äôt have too many columns to exclude (in this case, just the Name column). However, if you have a large dataset with many columns to exclude, or if it‚Äôs easier to specify the columns you want to compress directly, you can use a different method like cols =. For example, you could list out the columns you want to gather explicitly, or use a range of column names depending on the situation. This flexibility allows you to choose the most efficient method based on your dataset‚Äôs structure. performance_original |&gt; pivot_longer(cols = c(&quot;Eng_C1&quot;, &quot;Eng_C2&quot;, &quot;Eng_C3&quot;, &quot;Math_C1&quot;, &quot;Math_C2&quot;, &quot;Math_C3&quot;), names_to = &quot;Subject&quot;, values_to = &quot;Score&quot;) -&gt; performance performance ## # A tibble: 36 √ó 3 ## Name Subject Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Kelly Eng_C1 90 ## 2 Kelly Eng_C2 95 ## 3 Kelly Eng_C3 80 ## 4 Kelly Math_C1 90 ## 5 Kelly Math_C2 80 ## 6 Kelly Math_C3 97 ## 7 Liam Eng_C1 70 ## 8 Liam Eng_C2 80 ## 9 Liam Eng_C3 94 ## 10 Liam Math_C1 80 ## # ‚Ñπ 26 more rows Now, let‚Äôs dive a bit deeper into a more abstract concept. If we want to further split our data, for instance, breaking down the Subject column into two new columns, like Subject_em (for subject name) and Chapter (for chapter number), we can use the separate() function to accomplish this. performance |&gt; separate( col = Subject, into = c(&quot;Subject_em&quot;, &quot;Chapter&quot;), sep = &quot;[^[:alnum:]]+&quot;, remove = TRUE, convert = FALSE) -&gt; performance performance ## # A tibble: 36 √ó 4 ## Name Subject_em Chapter Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Kelly Eng C1 90 ## 2 Kelly Eng C2 95 ## 3 Kelly Eng C3 80 ## 4 Kelly Math C1 90 ## 5 Kelly Math C2 80 ## 6 Kelly Math C3 97 ## 7 Liam Eng C1 70 ## 8 Liam Eng C2 80 ## 9 Liam Eng C3 94 ## 10 Liam Math C1 80 ## # ‚Ñπ 26 more rows I know it looks scary, but please hear me out‚Äì this function will become one of your best friends once you understand itüòä. As mentioned eariler, we want to separate our Subject column into Subject_em and Chapter. So, we use col = to specify the target column (in this case, Subject), and into = to define the names of the two new columns we want to create. Now, let‚Äôs demystify the seemingly bizarre-looking sep = \"[^[:alnum:]]+\" part. In general, this means ‚Äúone or more non-alphabet or non-numeric characters‚Äù. Let‚Äôs break it down: [:alnum:] stands for alphabet (A-Z, a-z), and numbers (0-9). [^] means not include. + means one or more. When we combine these, it means we‚Äôre telling RStudio to look for one or more things that are not alphabet nor number. In this case, we want to find the underscore (_) and use it as the separation point. We also see the parameters remove = TRUE and convert = FALSE. These are defaults in the separate() function, but let‚Äôs briefly touch on them to understand what they do: remove = TRUE means to delete the original column Subject column after separating it. convert = FALSE ensures that RStudio doesn‚Äôt automatically change the types of the new columns. For exapmle, if the separation produces numbers (e.g., separating Eng_1 into Eng and 1), setting convert = TRUE would make the new 1 column numeric. We can change the column type later if needed, but for now, we keep it FALSE. Congratulations! You‚Äôve now learned how to pivot wide-format data into long-format, and how to separate columns. (Even after 5 years of learning and using RStuido, I‚Äôm still amazed by its power. EVERY SINGLE TIME.) If there‚Äôs a pivot_longer(), there must be a pivot_wider(), right? Well, yes! But as I mentioned earlier, RStudio prefers long-format data for analysis and visualization. For that reason (and for I am not proficient with pivot_wider()), I‚Äôm focusing on pivot_longer() here since it‚Äôs generally more useful for data analysis. (Maybe I‚Äôll dive into pivot_wider() when I‚Äôm more proficient with it, haha.) 6.2 join Another useful function when working with multiple datasets or files is combining them into one. Let‚Äôs continue with our performance dataset, and imagine that we have documented students‚Äô Biology exam scores in another dataset. performance_biology &lt;- data.frame( Name = c(&quot;Kelly&quot;, &quot;Liam&quot;, &quot;Henry&quot;, &quot;Alice&quot;, &quot;Jake&quot;, &quot;Dan&quot;), Bio_C1 = c(80, 80, 83, 93, 80, 88), Bio_C2 = c(73, 76, 75, 77, 79, 83), Bio_C3 = c(90, 93, 94, 90, 81, 82)) We pull the original performance data and want to add the Biology columns to it. performance_original |&gt; left_join(performance_biology, by = &quot;Name&quot;) ## Name Eng_C1 Eng_C2 Eng_C3 Math_C1 Math_C2 Math_C3 Bio_C1 Bio_C2 ## 1 Kelly 90 95 80 90 80 97 80 73 ## 2 Liam 70 80 94 80 89 79 80 76 ## 3 Henry 79 80 85 96 92 90 83 75 ## 4 Alice 98 93 89 83 72 74 93 77 ## 5 Jake 81 93 73 92 84 70 80 79 ## 6 Dan 79 70 91 68 83 92 88 83 ## Bio_C3 ## 1 90 ## 2 93 ## 3 94 ## 4 90 ## 5 81 ## 6 82 Here, we‚Äôve successfully added the Biology columns to the original dataset. When dealing with multiple independent variables (columns), you can use by = c(\"column1\", \"column2\", ‚Ä¶) to specify the join basis. Now, you might have guessed ‚Äì there is also a right_join() in RStudio. While I don‚Äôt use it as often as left_join() in my usual data analysis, it‚Äôs still important to understand the difference. left_join(): keeps the data from the left dataset, even if there is no matching data on the right. If no match is found, it fills the right columns with NA. right_join(): keeps the data from the right dataset, even if there is no matching data on the left. Again, unmatched data is filled with NA. While these functions are simple, they‚Äôre extremely powerful for combining datasets, and ‚Äì dare I say ‚Äì quite magical in what they can accomplish. 6.3 bind Besides left and right joins, there‚Äôs another way to combine datasets: binding. dataset1 &lt;- data.frame( brand = c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;), price = c(200, 300, 250), profit = c(100, 200, 200)) dataset2 &lt;- data.frame( brand = c(&quot;1&quot;,&quot;2&quot;,&quot;3&quot;), sales = c(20, 40, 60)) We have created two separate datassets. One contains a product‚Äôs brand, price, and profit, and the other contains sales numbers. We can use cbind() (column bind) to merge these datasets side by side. cbind(dataset1, dataset2) -&gt; merged_data merged_data ## brand price profit brand sales ## 1 1 200 100 1 20 ## 2 2 300 200 2 40 ## 3 3 250 200 3 60 However, as you might notice, the column brand is repeated in the merged data. If this repetition doesn‚Äôt affect your analysis, you can leave it. But if you prefer a cleaner result, you could opt to use left_join() instead, as it binds the data without duplicating columns. dataset1 |&gt; left_join(dataset2, by = &quot;brand&quot;) ## brand price profit sales ## 1 1 200 100 20 ## 2 2 300 200 40 ## 3 3 250 200 60 "],["statistical-analysis.html", "Chapter 7 Statistical Analysis 7.1 t-test 7.2 ANOVA 7.3 Post hoc analysis 7.4 Regression analysis", " Chapter 7 Statistical Analysis 7.1 t-test 7.1.1 example: Independent t-test Let‚Äôs start by analyzing the difference in strength between superheroes from different publishers. heroes2 |&gt; group_by(Publisher) |&gt; summarize(mean_strength = mean(Strength, na.rm = TRUE)) ## # A tibble: 4 √ó 2 ## Publisher mean_strength ## &lt;chr&gt; &lt;dbl&gt; ## 1 DC Comics 64.6 ## 2 George Lucas 33.3 ## 3 Image Comics 60 ## 4 Marvel Comics 43.1 We can observe from the dataset that the mean strength of superheroes from different publishers seems to vary. But, is this difference statistically significant? Let‚Äôs conduct a t-test to compare heroes from DC Comics and Marvel Comics. heroes2 |&gt; filter(Publisher %in% c(&quot;Marvel Comics&quot;, &quot;DC Comics&quot;)) |&gt; group_by(Publisher) |&gt; summarize(Strengths = list(Strength)) |&gt; with(t.test(Strengths[[1]], Strengths[[2]], paired = FALSE)) ## ## Welch Two Sample t-test ## ## data: Strengths[[1]] and Strengths[[2]] ## t = 2.8807, df = 32.441, p-value = 0.00698 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 6.297946 36.652054 ## sample estimates: ## mean of x mean of y ## 64.600 43.125 That looks complicated. I do not normally use that. 7.1.1.1 Step 1: Subset the data First, we need to subset the data into two groups: one for DC Comics and one for Marvel Comics. subset(heroes2, Publisher == &quot;Marvel Comics&quot;) -&gt; marvel subset(heroes2, Publisher == &quot;DC Comics&quot;) -&gt; DC 7.1.1.2 Step 2: Conduct the t-test Next, we use the t.test() function to calculate the difference in strength between the two groups. heroes2 |&gt; with(t.test(marvel$Strength, DC$Strength, paired = F)) ## ## Welch Two Sample t-test ## ## data: marvel$Strength and DC$Strength ## t = -2.8807, df = 32.441, p-value = 0.00698 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -36.652054 -6.297946 ## sample estimates: ## mean of x mean of y ## 43.125 64.600 From the results, we see that there is no significant difference in the strength levels between superheroes from DC Comics and Marcel Comics. Important Note: Independent vs Paired t-test In this case, we are comparing superheroes from two different groups (DC vs Marvel), which makes this an independent t-test. A paired t-test would be inappropriate here because the two groups consist of entirely different individuals. However, when comparing repeated measurements on the same group of people (e.g., before and after a task), a paired t-test would be more suitable. 7.1.2 example: Paired t-test Remember the performance data from earlier? Let‚Äôs say we want to analyze if there‚Äôs any difference in exam scores between Chapter 1 and Chapter 3 for the same group of students. We can perform a paired t-test in this case: # group them first subset(performance, Subject_em == &quot;Eng&quot; &amp; Chapter == &quot;C1&quot;) -&gt; eng_c1 subset(performance, Subject_em == &quot;Eng&quot; &amp; Chapter == &quot;C3&quot;) -&gt; eng_c3 performance |&gt; with(t.test(eng_c1$Score, eng_c3$Score, paired = T)) ## ## Paired t-test ## ## data: eng_c1$Score and eng_c3$Score ## t = -0.44114, df = 5, p-value = 0.6775 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -17.06789 12.06789 ## sample estimates: ## mean difference ## -2.5 This test checks whether the students‚Äô performance significantly changed between Chapter 1 and Chapter 3. The paired argument ensures that the test accounts for the fact that these are the same individuals in both conditions. 7.2 ANOVA ANOVA is a powerful statistical tool used to compare the means of multiple groups. It helps in determining whether the observed differences between group means are statistically significant. Here‚Äôs how we can use anova_test() in RStudio to perform various types of ANOVA. library(rstatix) heroes2 |&gt; anova_test( dv = # dependent variable, wid = # subject name/id, type = NULL, # default: type II ANOVA between = # between-subject independent variable, within = # within-subject independent variable, effect.size = &quot;ges&quot;, error = NULL, white.adjust = FALSE, observed = NULL, detailed = TRUE) detailed = TRUE: Requests a more detailed statistical output. FALSE is the default. type = NULL: Type 2 ANOVA is the default. You can change this to 1 or 3 based on your needs. effect.size =: Computes effect size, the default is using generalizing eta squared (ges) or partial eta squared (pes). to compute. The Help section in RStudio says I could choose both, but I haven‚Äôt figure out how to do so yet. For ANCOVA, you can add covariate = to include continuous variables as covariates. Insert it below within =, above type =. 7.2.1 one-way ANOVA One-way ANOVA is used when we have one independent variable (IV) and one dependent variable (DV). 7.2.1.1 example 1: Strength ~ Intelligence IV: Intelligence DV: Strength heroes2 |&gt; anova_test( dv = Strength, wid = Name, between = Intelligence, detailed = T) ## ANOVA Table (type II tests) ## ## Effect SSn SSd DFn DFd F p p&lt;.05 ges ## 1 Intelligence 8758.544 129262 4 136 2.304 0.062 0.063 7.2.1.2 example 2: Strength ~ Gender IV: Gender DV: Strength heroes2 |&gt; anova_test( dv = Strength, wid = Name, between = Gender, detailed = T) ## ANOVA Table (type II tests) ## ## Effect SSn SSd DFn DFd F p p&lt;.05 ges ## 1 Gender 3772.182 134248.4 1 139 3.906 0.05 0.027 7.2.2 two-way ANOVA Two-way ANOVA is used when we have two independent variables and one dependent variable. Here, we look at how these two IVs interact with each other. 7.2.2.1 example 1: Strength ~ BMI_status * Gender heroes2 |&gt; anova_test( dv = Strength, wid = Name, between = c(Gender, BMI_status), detailed = TRUE) ## ANOVA Table (type III tests) ## ## Effect SSn SSd DFn DFd F p ## 1 (Intercept) 68473.044 109803.3 1 133 82.938 1.11e-15 ## 2 Gender 51.278 109803.3 1 133 0.062 8.04e-01 ## 3 BMI_status 8413.707 109803.3 3 133 3.397 2.00e-02 ## 4 Gender:BMI_status 6885.839 109803.3 3 133 2.780 4.40e-02 ## p&lt;.05 ges ## 1 * 0.384000 ## 2 0.000467 ## 3 * 0.071000 ## 4 * 0.059000 Note: Be mindful of the ANOVA type. Even if you don‚Äôt specify a type, RStudio may default to type III ANOVA. If you prefer type II ANOVA, specify type = 2. 7.2.2.2 example 2: strength ~ gender * BMI heroes2 |&gt; anova_test( dv = Strength, wid = Name, between = c(Gender, BMI), detailed = T) However, we would encounter an error here. Why is that? Step 1: Check for mismatched variable types. For example, putting both categorical (e.g., Gender) and numerical (e.g., BMI) in the between = section. Solution 1 convert numerical variables into categorical variables For example, you can classify BMI into levels like obese, overweight, normal, and underweight. (We did this in the previous section.) # Solution 1 heroes2 |&gt; anova_test( dv = Strength, wid = Name, between = c(Gender, BMI_status), detailed = T) ## ANOVA Table (type III tests) ## ## Effect SSn SSd DFn DFd F p ## 1 (Intercept) 68473.044 109803.3 1 133 82.938 1.11e-15 ## 2 Gender 51.278 109803.3 1 133 0.062 8.04e-01 ## 3 BMI_status 8413.707 109803.3 3 133 3.397 2.00e-02 ## 4 Gender:BMI_status 6885.839 109803.3 3 133 2.780 4.40e-02 ## p&lt;.05 ges ## 1 * 0.384000 ## 2 0.000467 ## 3 * 0.071000 ## 4 * 0.059000 Solution 2 use ANCOVA (Analysis of Covariance) (continuous * category ~ continuous) ANCOVA is suitable when you have continuous variable that you want to adjust for or control while analyzing the main effects of categorical independent variables. In ANCOVA, you can include the continuous variable as a covariate. # Solution 2 (ANCOVA) heroes2 |&gt; anova_test( dv = Strength, wid = Name, between = Gender, covariate = BMI, detailed = T) ## ANOVA Table (type II tests) ## ## Effect SSn SSd DFn DFd F p p&lt;.05 ges ## 1 BMI 23336.275 110912.1 1 138 29.036 2.99e-07 * 1.74e-01 ## 2 Gender 10.606 110912.1 1 138 0.013 9.09e-01 9.56e-05 In Solution 2, the BMI variable is used as a covariate. This allows you to account for the continuous variable (BMI) while examining the effect of gender on strength. 7.2.2.3 example 3: strength ~ gender * Intelligence Let us take a look at another example. In the heroes2 dataset, the Intelligence is a categorical variable. The intelligence levels of superheroes are labelled as high, good, average, moderate, and low. heroes2 |&gt; distinct(Intelligence) ## # A tibble: 5 √ó 1 ## Intelligence ## &lt;chr&gt; ## 1 moderate ## 2 good ## 3 high ## 4 average ## 5 low Therefore, we should not encounter the same problem as example 2. heroes2 |&gt; anova_test( dv = Strength, wid = Name, between = c(Gender, Intelligence), detailed = T) However, we still see errors here. After examining Step 1, we can conclude that it is not the issue here. We can try to debug using the following methods: Step 2 We examine both independent variables separately to ensure they are functioning properly individually. We can delete one of the variables each time for testing. (Although this is usually not the problem, it‚Äôs still good practice to check.) Checking the variable Gender heroes2 |&gt; anova_test( dv = Strength, wid = Name, between = Gender, detailed = T) ## ANOVA Table (type II tests) ## ## Effect SSn SSd DFn DFd F p p&lt;.05 ges ## 1 Gender 3772.182 134248.4 1 139 3.906 0.05 0.027 Checking the variable Intelligence heroes2 |&gt; anova_test( dv = Strength, wid = Name, between = Intelligence, detailed = T) ## ANOVA Table (type II tests) ## ## Effect SSn SSd DFn DFd F p p&lt;.05 ges ## 1 Intelligence 8758.544 129262 4 136 2.304 0.062 0.063 Both variables look fine, and the code works smoothly when tested individually. Step 3 We examine if there are any missing values in any of the category. (I often forgot about this step, and spend hours confused about why my ANOVA isn‚Äôt ANOVAing‚Ä¶) table(heroes2$Gender, heroes2$Intelligence) ## ## average good high low moderate ## F 14 20 4 0 2 ## M 24 41 27 2 7 Here, we see that in female superheroes category, there is a zero for low intelligence level. This prevents the ANOVA from proceeding. Now that we have identified the problem, we can remove the intelligence == \"low\" from our analysis, as it hinders the process. heroes2 |&gt; filter(Intelligence != &quot;low&quot;) |&gt; anova_test( dv = Strength, wid = Name, between = c(Gender, Intelligence), type = 2, detailed = T) ## ANOVA Table (type II tests) ## ## Effect SSn SSd DFn DFd F p p&lt;.05 ## 1 Gender 1982.076 126823.2 1 131 2.047 0.155 ## 2 Intelligence 3719.933 126823.2 3 131 1.281 0.284 ## 3 Gender:Intelligence 406.757 126823.2 3 131 0.140 0.936 ## ges ## 1 0.015 ## 2 0.028 ## 3 0.003 You might think: ‚ÄúI‚Äôll just add group_by() before the anova_test().‚Äù However, while this approach would not give you error message, it would not yield a two-way ANOVA as we intended. Instead, it would just separate the data into two groups before performing a one-way ANOVA on each. See the codes below: heroes2 |&gt; filter(Intelligence != &quot;low&quot;) |&gt; group_by(Gender) |&gt; anova_test( dv = Strength, wid = Name, between = Intelligence, detailed = T) ## # A tibble: 2 √ó 10 ## Gender Effect SSn SSd DFn DFd F p `p&lt;.05` ges ## * &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 F Intelli‚Ä¶ 1564. 33535. 3 36 0.56 0.645 &quot;&quot; 0.045 ## 2 M Intelli‚Ä¶ 2563. 93288. 3 95 0.87 0.46 &quot;&quot; 0.027 We can see that the result table differs from the two-way ANOVA table (refer to the upper table), and the numbers are also different (see DFn and DFd in both results). 7.2.3 three-way ANOVA 7.2.3.1 example 1: Strength ~ Gender * Intelligence * BMI_status If we want to add more independent variables, we can simply include additional column names in the between = section. heroes2 |&gt; filter(Intelligence != &quot;low&quot;) |&gt; anova_test( dv = Strength, wid = Name, between = c(Gender, Intelligence, BMI_status), type = 2, detailed = T) ## ANOVA Table (type II tests) ## ## Effect SSn SSd DFn DFd F ## 1 Gender 1083.194 96626.99 1 118 1.323 ## 2 Intelligence 3465.586 96626.99 3 118 1.411 ## 3 BMI_status 16524.941 96626.99 3 118 6.727 ## 4 Gender:Intelligence 2703.193 96626.99 2 118 1.651 ## 5 Gender:BMI_status 8295.111 96626.99 3 118 3.377 ## 6 Intelligence:BMI_status 7715.048 96626.99 7 118 1.346 ## 7 Gender:Intelligence:BMI_status NA 96626.99 0 118 NA ## p p&lt;.05 ges ## 1 0.252000 0.011 ## 2 0.243000 0.035 ## 3 0.000314 * 0.146 ## 4 0.196000 0.027 ## 5 0.021000 * 0.079 ## 6 0.235000 0.074 ## 7 NA &lt;NA&gt; NA Note that if the independent variable is within-subject (in the case of a mixed analysis), we place the within-subject independent variables in the within = section. This is commonly used when analyzing experimental results, such as comparing test scores before learning and after learning. See below for more details on mixed ANOVA. 7.2.4 mixed ANOVA As mentioned, mixed ANOVA is often used for analyzing experimental results, as it allows for tracking individual changes over time, which is difficult to achieve with other methods. Let‚Äôs assume a high school wants to investigate whether different teaching styles affect students‚Äô exam scores. They conducted an experiments, dividing students into two groups: one received education in a fun way, while the other was taught in a more rigid manner. The school also tested the students before and after learning the subject. Independent variable: teaching style (fun/rigid), exam time (before/after) Dependent variable: exam score teaching_style &lt;- data.frame( student = c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;, &quot;5&quot;, &quot;6&quot;), style = as.factor(c(&quot;fun&quot;, &quot;rigid&quot;, &quot;fun&quot;, &quot;rigid&quot;, &quot;fun&quot;, &quot;rigid&quot;, &quot;fun&quot;, &quot;rigid&quot;, &quot;fun&quot;, &quot;rigid&quot;, &quot;fun&quot;, &quot;rigid&quot;)), timing = as.factor(c(&quot;before&quot;, &quot;before&quot;, &quot;before&quot;, &quot;before&quot;, &quot;before&quot;, &quot;before&quot;, &quot;after&quot;, &quot;after&quot;, &quot;after&quot;, &quot;after&quot;, &quot;after&quot;, &quot;after&quot;)), score = c(50, 13, 10, 70, 23, 70, 70, 90, 66, 83, 80, 80)) The data frame is created with 6 students: 3 participated in the fun teaching style, and 3 experienced the rigid style. All of their before and after exam scores were recorded. Here, we want to see if the teaching style influenced their exam scores. teaching_style |&gt; anova_test( dv = score, wid = student, between = style, within = timing, detailed = T) ## ANOVA Table (type II tests) ## ## Effect DFn DFd SSn SSd F p p&lt;.05 ## 1 (Intercept) 1 4 41418.750 1278.667 129.569 0.00034 * ## 2 style 1 4 954.083 1278.667 2.985 0.15900 ## 3 timing 1 4 4524.083 1876.667 9.643 0.03600 * ## 4 style:timing 1 4 90.750 1876.667 0.193 0.68300 ## ges ## 1 0.929 ## 2 0.232 ## 3 0.589 ## 4 0.028 From the analysis, we can observe that teaching style does not have a significant impact on their scores. However, there is a main effect of the timing variable. By examining the mean scores across different times, we can see that students performed better after learning, regardless of the teaching style applied. teaching_style |&gt; group_by(timing) |&gt; summarise(mean_score = mean(score)) ## # A tibble: 2 √ó 2 ## timing mean_score ## &lt;fct&gt; &lt;dbl&gt; ## 1 after 78.2 ## 2 before 39.3 Additional notes Use filter() to choose specific groups for analysis. For instance, filter(Intelligence %in% c(\"high\", \"good\") or filter(Hair_color != \"No Hair\"). group_by() is useful if you want to examine ANOVA results for both conditions‚Äô simultaneously. 7.3 Post hoc analysis After conducting an ANOVA, if we want to explore the data further (assuming the ANOVA results are significant), we can perform a post hoc analysis. I used to be confused about the difference between post hoc analysis and pairwise t-test. It‚Äôs important to note that post hoc analysis is done after obtaining a significant result from ANOVA, while pairwise t-test can be applied to any two groups of data. teaching_style |&gt; group_by(style) |&gt; pairwise_t_test( score ~ timing, paired = TRUE, p.adjust.method = &quot;bonferroni&quot;) ## # A tibble: 2 √ó 11 ## style .y. group1 group2 n1 n2 statistic df p p.adj ## * &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 fun score after before 3 3 3.64 2 0.068 0.068 ## 2 rigid score after before 3 3 1.53 2 0.267 0.267 ## # ‚Ñπ 1 more variable: p.adj.signif &lt;chr&gt; In this example, we use post hoc analysis: score ~ timing: Here, we put the dependent variable on the left and the independent variable on the right. We are comparing scores across different exam timing. paired =: Set this to TRUE if it‚Äôs a repeated measures design , and FALSE if it‚Äôs a between-subject design (i.e., different participants in each group). p.adjust.method: This argument allows us to choose a method for adjusting p values. 7.4 Regression analysis "],["data-visualization.html", "Chapter 8 Data Visualization 8.1 bar chart 8.2 scatter plot 8.3 box plot 8.4 histogram 8.5 density plot 8.6 mixed graphs 8.7 additional features on the plot 8.8 ‰∏çÁü•ÈÅìÊÄéÈ∫ºÊîπlabelÊ¨∏ È†≠Áóõ „Ñû ÂèØ‰ª•mutate‰ΩÜÂ•ΩÈ∫ªÁÖ©ÂëÄ", " Chapter 8 Data Visualization 8.1 bar chart Let‚Äôs use a new dataset as an example here. In the lego_sample dataset, there are various LEGO sets, pieces, recommended retail prices, prices on Amazon, sizes, and more. library(openintro) lego_sample ## # A tibble: 75 √ó 14 ## item_number set_name theme pieces price amazon_price year ages ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 10859 My Firs‚Ä¶ DUPL‚Ä¶ 6 4.99 16 2018 Ages‚Ä¶ ## 2 10860 My Firs‚Ä¶ DUPL‚Ä¶ 6 4.99 9.45 2018 Ages‚Ä¶ ## 3 10862 My Firs‚Ä¶ DUPL‚Ä¶ 41 15.0 39.9 2018 Ages‚Ä¶ ## 4 10864 Large P‚Ä¶ DUPL‚Ä¶ 71 50.0 56.7 2018 Ages‚Ä¶ ## 5 10867 Farmers‚Ä¶ DUPL‚Ä¶ 26 20.0 37.0 2018 Ages‚Ä¶ ## 6 10870 Farm An‚Ä¶ DUPL‚Ä¶ 16 9.99 9.99 2018 Ages‚Ä¶ ## 7 10872 Train B‚Ä¶ DUPL‚Ä¶ 26 25.0 22.0 2018 Ages‚Ä¶ ## 8 10875 Cargo T‚Ä¶ DUPL‚Ä¶ 105 120. 129. 2018 Ages‚Ä¶ ## 9 10876 Spider-‚Ä¶ DUPL‚Ä¶ 38 30.0 74.5 2018 Ages‚Ä¶ ## 10 10878 Rapunze‚Ä¶ DUPL‚Ä¶ 37 30.0 99.0 2018 Ages‚Ä¶ ## # ‚Ñπ 65 more rows ## # ‚Ñπ 6 more variables: pages &lt;dbl&gt;, minifigures &lt;dbl&gt;, ## # packaging &lt;chr&gt;, weight &lt;chr&gt;, unique_pieces &lt;dbl&gt;, size &lt;chr&gt; lego_sample |&gt; na.omit() |&gt; ggplot(aes(x = packaging, y = pieces)) + geom_bar(stat = &quot;summary&quot;, position = position_dodge(.8), width = .7, fill = &quot;#BDD5EA&quot;) + geom_errorbar(stat = &quot;summary&quot;, position = position_dodge(0.5), width = .12) + facet_wrap(theme ~ ., scales = &quot;free&quot;) It seems that a lot has happened in the code chunk, and there‚Äôs quite a bit of information presented by the graphs. Let‚Äôs walk through the code. in ggplot(), we specify the x and y axes. geom_bar() creates the bar chart. stat = \"summary\" calculates the mean value of the y-axis variable, which is pieces in this case. position = position_dodge() separates the bars to avoid overlap. width = sets the width of the bars. If width = 1, the bars will stick together. fill = can be a single color (as in this example) or another variable to create color variation. geom_errorbar() calculates and displays the standard error on the graph. The width, fill, and position arguments work similarly to those in geom_bar(). facet_wrap() separates the graphs by the variable you specify. You can use &lt;your variable&gt; ~ . or ~ &lt;your variable&gt;. The scales = \"free\" option adjusts the y-axis for each graph based on its data. However, it‚Äôs not always recommended, as explained below. Now, let‚Äôs analyze the graph. We can observe a few things: The graphs are separated by different LEGO themes: ‚ÄúDUPLO¬Æ‚Äù, ‚ÄúFriends‚Äù, and ‚ÄúCity‚Äù. In the ‚ÄúFriends‚Äù and ‚ÄúCity‚Äù collections, there are only data from the Box packaging method, indicating that there is no data where the LEGO is from ‚ÄúCity‚Äù or ‚ÄúFriends‚Äù collections using Plastic box. The y-axis scales differ across the graphs. Although the program automatically adjusts the scale based on the data, this might hinder important information. For example, in the ‚ÄúCity‚Äù and ‚ÄúFriends‚Äù collections, the difference in pieces is harder to discern. We will explain how to address this in the scales section. If we do not want to use facet_wrap() for separating graphs, we can use other ways to distinguish between categories. For exapmle, if we assign a variable to fill =, we can ask RStudio to fill different colors for each category. lego_sample |&gt; na.omit() |&gt; ggplot(aes(x = packaging, y = pieces, fill = theme)) + geom_bar(stat = &quot;summary&quot;, position = position_dodge(.8), width = .7) + geom_errorbar(stat = &quot;summary&quot;, position = position_dodge(.8), width = .12) 8.2 scatter plot lego_sample |&gt; na.omit() |&gt; ggplot(aes(x = pieces, y = price, color = theme, shape = theme)) + geom_point() + geom_smooth(method = &quot;lm&quot;) Let‚Äôs examine the code: In the aes() section, I‚Äôve used both color AND shape to differentiate by theme. Usually, one type of distinction is sufficient, but sometimes colors alone may be hard to differentiate. In such cases, adding another feature (e.g., shape) can improve readability. geom_point() is used to display individual data point, creating the scatter plot. geom_smooth() adds trend lines to the data. By setting method = \"lm\", we apply a linear model, which results in a straight trend line. Next, let‚Äôs try a different dataset: movies. This dataset is part of the openintro package and contains several datasets. install.packages(&quot;openintro&quot;) library(&quot;openintro&quot;) movies ## # A tibble: 140 √ó 5 ## movie genre score rating box_office ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2Fast2Furious action 48.9 PG-13 127. ## 2 28DaysLater horror 78.2 R 45.1 ## 3 AGuyThing rom-comedy 39.5 PG-13 15.5 ## 4 AManApart action 42.9 R 26.2 ## 5 AMightyWind comedy 79.9 PG-13 17.8 ## 6 AgentCodyBanks action 57.9 PG 47.8 ## 7 Alex&amp;Emma rom-comedy 35.1 PG-13 14.2 ## 8 AmericanWedding comedy 50.7 R 104. ## 9 AngerManagement comedy 62.6 PG-13 134. ## 10 AnythingElse rom-comedy 63.3 R 3.21 ## # ‚Ñπ 130 more rows The dataset contains 5 columns and 140 rows, representing movies released in 2003. The columns include the movie title, genre, score (by critics on a scale 0-100), MPAA rating, and box_office (millions of dollars earned at the box office in the US and Canada.) You can type movies in the help section in the bottom-right panel for a detailed description of the data. movies |&gt; ggplot(aes(x = box_office, y = score)) + geom_point() + geom_smooth(method = &quot;lm&quot;) From the graph, we can see a positive relationship between the box_office and score. 8.3 box plot A box plot helps us visualize the interquartile range in our data. This is useful when comparing a categorical variable with numerical values. movies |&gt; ggplot(aes(x = score, y = rating)) + geom_boxplot() 8.4 histogram movies |&gt; ggplot(aes(x = score)) + geom_histogram() movies |&gt; ggplot(aes(x = score)) + geom_histogram(binwidth = 1) movies |&gt; ggplot(aes(x = score)) + geom_histogram(binwidth = 10) binwidth: controls the thickness of the bars, if the bars are too thin (binwidth = 1), you‚Äôll see individual data points clearly. However, this may not be ideal for observing general trends in the data. Therefore, I recommend experimenting with different binwidth values to find what works best for your data. movies |&gt; ggplot(aes(x = score, color = rating)) + geom_histogram(binwidth = 5) In the histogram, the color argument controls the outline color of the bar, while fill controls the interior color of the bars. movies |&gt; ggplot(aes(x = score, fill = rating)) + geom_histogram(binwidth = 5) 8.5 density plot Density plots are similar to connecting the peaks of a histogram to form a smooth line, providing a clearer view of the data distribution. movies |&gt; ggplot(aes(x = score)) + geom_density() We can also separate data into subcategories. movies |&gt; ggplot(aes(x = score, fill = rating, color = rating)) + geom_density() However, this graph might be hard to read due to overlapping data. For instance, the values for ratings R and PG-13 are not clearly distinguishable. To resolve this, we can adjust the transparancy of the graph. movies |&gt; ggplot(aes(x = score, fill = rating, color = rating)) + geom_density(alpha = 0.5) Alternatively, we can use geom_density_ridges() to further separate the data, improving readability. install.packages(&quot;ggridges&quot;) library(ggridges) movies |&gt; ggplot(aes(x = score,y = rating, fill = rating, color = rating)) + geom_density_ridges(alpha = 0.6) 8.6 mixed graphs We will now create mixed graphs using another package: GGally. install.packages(&quot;GGally&quot;) library(GGally) 8.6.1 categorical * numeric ÈÄôÈÇäÁöÑË≥áÊñôÂú®‰∏ãÈù¢ÊâçÊúâ‰ªãÁ¥πÔºå‰∏çÁü•ÈÅìÊòØË¶ÅÊää‰ªãÁ¥πÊèêÂâçÈÇÑÊòØÊÄéÊ®£ÔºöÔº§ lego_sample ## # A tibble: 75 √ó 14 ## item_number set_name theme pieces price amazon_price year ages ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 10859 My Firs‚Ä¶ DUPL‚Ä¶ 6 4.99 16 2018 Ages‚Ä¶ ## 2 10860 My Firs‚Ä¶ DUPL‚Ä¶ 6 4.99 9.45 2018 Ages‚Ä¶ ## 3 10862 My Firs‚Ä¶ DUPL‚Ä¶ 41 15.0 39.9 2018 Ages‚Ä¶ ## 4 10864 Large P‚Ä¶ DUPL‚Ä¶ 71 50.0 56.7 2018 Ages‚Ä¶ ## 5 10867 Farmers‚Ä¶ DUPL‚Ä¶ 26 20.0 37.0 2018 Ages‚Ä¶ ## 6 10870 Farm An‚Ä¶ DUPL‚Ä¶ 16 9.99 9.99 2018 Ages‚Ä¶ ## 7 10872 Train B‚Ä¶ DUPL‚Ä¶ 26 25.0 22.0 2018 Ages‚Ä¶ ## 8 10875 Cargo T‚Ä¶ DUPL‚Ä¶ 105 120. 129. 2018 Ages‚Ä¶ ## 9 10876 Spider-‚Ä¶ DUPL‚Ä¶ 38 30.0 74.5 2018 Ages‚Ä¶ ## 10 10878 Rapunze‚Ä¶ DUPL‚Ä¶ 37 30.0 99.0 2018 Ages‚Ä¶ ## # ‚Ñπ 65 more rows ## # ‚Ñπ 6 more variables: pages &lt;dbl&gt;, minifigures &lt;dbl&gt;, ## # packaging &lt;chr&gt;, weight &lt;chr&gt;, unique_pieces &lt;dbl&gt;, size &lt;chr&gt; Let‚Äôs say we want to explore the relationship between the price of Lego sets (price, a continuous numeric variable) and their size (size, a categorical variable). lego_sample |&gt; ggpairs(columns = c(&quot;price&quot;, &quot;size&quot;)) The top-left panel of the resulting plot shows the distribution of the price ‚Äì a univariate plot of price vs.¬†itself. The bottom-right panel shows the distribution of size, where RStudio counts the number of Lego sets in each category (large and small). The top-right panel presents a boxplot of price vss size, which is commonly used for visualizing the relationship between numeric variable and categorical variable. Similarly, the bottom-left panel shows the distribution of prices within each size category, but it doesn‚Äôt specify which data belongs to large or small categories (possibly because I‚Äôm just couldn‚Äôt figure it out yet). 8.6.2 numeric * numeric Next, let‚Äôs examine two numerical variables: the recommended retail price (price) and the price on Amazon (amazon_price). lego_sample |&gt; ggpairs(columns = c(&quot;price&quot;, &quot;amazon_price&quot;)) This graph differs from the previous one because both variables are numeric. The top-left panel shows a density plot of the recommended retail price, while the bottom-right panel does the amazon_price. Although the distributions are similar, they are not identical. In the bottom-right panel, a scatter plot shows a strong positive correlation between the two prices, as reflected by the correlation coefficient displayed in the top-right panel. 8.6.3 numeric * numeric * numeric What if we add one more numeric variable? We can take a look at the relationship between price, amazon_price, and minifigures (after converting minifigures back to a numeric variable). lego_sample |&gt; ggpairs(columns = c(&quot;price&quot;, &quot;amazon_price&quot;, &quot;minifigures&quot;)) This gives us a clearer overview of the relationship between multiple numeric variables. If we want to add more information, like trend lines or confidence intervals, we can use the following code: lego_sample |&gt; ggpairs(columns = c(&quot;price&quot;, &quot;amazon_price&quot;, &quot;minifigures&quot;), lower = list(continuous = wrap(&quot;smooth&quot;))) Here, we simply add lower = and specify what we want. lower =: Controls the display of the lower part of the graph. wrap(): Helps us to specify what we want for continuous numeric variables. smoooth: Creates trend lines on the scatter plot (similar to geom_smooth). continuous =: Specifies that the data is continuous, allowing us to adjust how it‚Äôs displayed. Note that the default correlation method is \"pearson\". To change this, you can add the mehtod = argument to specify another correlation method. lego_sample |&gt; ggpairs(columns = c(&quot;price&quot;, &quot;amazon_price&quot;, &quot;minifigures&quot;), upper = list(continuous = wrap(&quot;cor&quot;, method = &quot;spearman&quot;)), lower = list(continuous = wrap(&quot;smooth&quot;))) For the upper = part of the graph: upper = \"cor\": Displays the correlation coefficients in the upper panels. 8.6.4 numeric * numeric * numeric * categorical Now that we‚Äôve explore several ways to plot numeric variables, let‚Äôs add a categorical variable here. A good way to differentiate groups is by assigning colors to categories in the aes() function. #you have learned a few ways to deal with plots inside ggpairs(). Let us add some colors on it (literally). Here‚Äôs an example: lego_sample |&gt; ggpairs(columns = c(&quot;price&quot;, &quot;amazon_price&quot;, &quot;minifigures&quot;, &quot;size&quot;), mapping = aes(color = size, alpha = .7), upper = list(continuous = wrap(&quot;cor&quot;, method = &quot;spearman&quot;)), lower = list(continuous = wrap(&quot;smooth&quot;))) Adding transparency (alpha =) helps reduce clutter in the plot by making overlapping graphs easier to distinguish. Below is another coding style to achieve the same result, which I prefer. It separates the column selection step from the plotting step, making the code easier to manage. lego_sample |&gt; select(price, amazon_price, minifigures, size) |&gt; ggpairs(mapping = aes(color = size, alpha = .7), upper = list(continuous = wrap(&quot;cor&quot;, method = &quot;spearman&quot;)), lower = list(continuous = wrap(&quot;smooth&quot;))) Although ggpairs() is useful for exploring relationships between different variables (e.g., comparing test scores), it can sometimes become overwhelming with too many plots. If you‚Äôre unsure whether this approach is the best for your data, I recommend creating individual plots first (e.g., density or box plots) before mixing everything together. This will help clarify the relationships you want to explore and the most effective ways to visualize them. 8.7 additional features on the plot 8.7.1 labels A good graph includes informative labels. While you could add titles, subtitles, and other labels in separate software after downloading the graph, it‚Äôs more efficient and reduces the chance of errors if you add all the labels directly in RStudio. movies |&gt; ggplot(aes(x = score,y = rating, fill = rating, color = rating)) + geom_density_ridges(alpha = 0.6) + labs( title = &quot;Movie Scores of Different MPAA Ratings.&quot;, subtitle = &quot;Put your subtitle here because I don&#39;t know what to say.&quot;, x = &quot;Movie Score&quot;, y = &quot;MPAA Rating&quot;, fill = &quot;Rating&quot;, color = &quot;Rating&quot;, caption = &quot;sources: movies from openintro&quot;) If you prefer not to show certain labels, you can aslo specify this in the code and let the program remove them for you. movies |&gt; ggplot(aes(x = score,y = rating, fill = rating, color = rating)) + geom_density_ridges(alpha = 0.6) + labs( x = NULL, fill = NULL, color = NULL, fill = NULL) For example, in the code chunk above, when we set the x-axis to NULL, the label disappears from the graph. However, if we don‚Äôt specify the y-axis in the labs() function, the original label from the data will still appear. Also, if you want to remove the legend, you can do so by adjusting the theme() function. movies |&gt; ggplot(aes(x = score,y = rating, fill = rating, color = rating)) + geom_density_ridges(alpha = 0.6) + labs(x = NULL, y = NULL) + theme(legend.position = &quot;hide&quot;) 8.8 ‰∏çÁü•ÈÅìÊÄéÈ∫ºÊîπlabelÊ¨∏ È†≠Áóõ „Ñû ÂèØ‰ª•mutate‰ΩÜÂ•ΩÈ∫ªÁÖ©ÂëÄ 8.8.1 colors Let‚Äôs demonstrate how to change colors in a graph with the lego_sample dataset! lego_sample |&gt; na.omit() |&gt; ggplot(aes(x = size, y = price, fill = as.factor(minifigures))) + geom_bar(stat = &quot;summary&quot;, position = &quot;dodge&quot;) For easier demonstration, we will focus on LEGO sets with 1 to 3 minifigures. lego_sample |&gt; na.omit() |&gt; filter(minifigures &lt;= 3) |&gt; ggplot(aes(x = size, y = price, fill = as.factor(minifigures))) + geom_bar(stat = &quot;summary&quot;, position = &quot;dodge&quot;) Now we‚Äôre all set! lego_sample |&gt; na.omit() |&gt; filter(minifigures &lt;= 3) |&gt; ggplot(aes(x = size, y = price, fill = as.factor(minifigures))) + geom_bar(stat = &quot;summary&quot;, position = &quot;dodge&quot;) + scale_fill_manual(values = c(&quot;darkblue&quot;,&quot;yellow&quot;,&quot;pink&quot;)) It‚Äôs as simple as that! Also, note that you only need to specify each color once. For instance, although the colors \"darkblue\", \"yellow\", and \"pink\" appear twice in the graph, we only need to type them once in stead of using values = c(\"darkblue\", \"yellow\", \"pink\", \"darkblue\", \"yellow\", \"pink\"). If you don‚Äôt want to use default colors but don‚Äôt feel like manually selecting distinct colors each time, you can use pre-existing color palettes in RStudio. install.packages(&quot;viridis&quot;) library(viridis) You can also add outlines to the bars in the chart to make them pop up more. lego_sample |&gt; na.omit() |&gt; filter(minifigures &lt;= 3) |&gt; ggplot(aes(x = size, y = price, fill = as.factor(minifigures))) + geom_bar(stat = &quot;summary&quot;, position = &quot;dodge&quot;, color = &quot;black&quot;) + scale_fill_viridis_d() Note that we use scale_fill_viridis_d() here. If you‚Äôre using color = instead of fill =, remember to switch to scale_color_viridis_d(). lego_sample |&gt; na.omit() |&gt; filter(minifigures &lt;= 3) |&gt; ggplot(aes(x = size, y = price, color = as.factor(minifigures))) + geom_bar(stat = &quot;summary&quot;, position = &quot;dodge&quot;, fill = &quot;white&quot;) + scale_color_viridis_d() 8.8.2 scales Now, let‚Äôs look at some data from heroes2 dataset. heroes2 |&gt; filter(Intelligence %in% c(&quot;good&quot;, &quot;high&quot;)) |&gt; ggplot(aes(x = Gender, y = Strength)) + geom_bar(stat = &quot;summary&quot;, position = position_dodge(.8), width = .7) + geom_errorbar(stat = &quot;summary&quot;, position = position_dodge(0.5), width = .12) + facet_wrap(Intelligence ~ ., scales = &quot;free&quot;) Take a quick glance at the chart. It seems like the good intelligence group has higher strength than the high intelligence group as the bar is higher. But is that really the case? Take a closer look at the two bar charts. The y-axis scales are different from one graph to another. To verify, let‚Äôs calculate the average strength for both groups. heroes2 |&gt; filter(Intelligence %in% c(&quot;good&quot;, &quot;high&quot;)) |&gt; group_by(Intelligence, Gender) |&gt; summarise(mean_strength = mean(Strength)) ## # A tibble: 4 √ó 3 ## # Groups: Intelligence [2] ## Intelligence Gender mean_strength ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 good F 34 ## 2 good M 45.4 ## 3 high F 55 ## 4 high M 57.0 We can see from the results that in the good intelligence group, the average strength of both genders is actually lower than in the high intelligence group. However, without paying attention to the y-axis, we might have gotten the wrong impression that the good intelligence group had higher strength than the high intelligence group. To fix this issue, we can manually adjust the scale using coord_cartesian(). You can choose to remove scales = \"free\" or leave it there. Since the code is applied in layers, if you add the manual scale after specifying scales = \"free\", the graph will be unaffected. heroes2 |&gt; filter(Intelligence %in% c(&quot;good&quot;, &quot;high&quot;)) |&gt; ggplot(aes(x = Gender, y = Strength)) + geom_bar(stat = &quot;summary&quot;, position = position_dodge(.8), width = .7, fill = &quot;#BDD5EA&quot;) + geom_errorbar(stat = &quot;summary&quot;, position = position_dodge(0.5), width = .12) + facet_wrap(Intelligence ~ ., scales = &quot;free&quot;) + coord_cartesian(ylim = c(0,100)) After setting the same scale for all graphs, it becomes much easier to compare them and observe relationships between variables. You can modify the ylim() values based on your data. 8.8.3 themes The theme() function allows you to change the overall appearance of your graph. Some commonly used themes are theme_classic(), theme_light(), and the default theme_gray(). "],["efficiency-tips-for-data-processing.html", "Chapter 9 Efficiency Tips for Data Processing", " Chapter 9 Efficiency Tips for Data Processing "],["data-export.html", "Chapter 10 Data Export", " Chapter 10 Data Export "],["colclusion-and-advanced-learning.html", "Chapter 11 Colclusion and Advanced Learning", " Chapter 11 Colclusion and Advanced Learning "],["hello-bookdown.html", "Chapter 12 Hello bookdown 12.1 A section", " Chapter 12 Hello bookdown All chapters start with a first-level heading followed by your chapter title, like the line above. There should be only one first-level heading (#) per .Rmd file. 12.1 A section All chapter sections start with a second-level (##) or higher heading followed by your section title, like the sections above and below here. You can have as many as you want within a chapter. An unnumbered section Chapters and sections are numbered by default. To un-number a heading, add a {.unnumbered} or the shorter {-} at the end of the heading, like in this section. "],["cross.html", "Chapter 13 Cross-references 13.1 Chapters and sub-chapters 13.2 Captioned figures and tables", " Chapter 13 Cross-references Cross-references make it easier for your readers to find and link to elements in your book. 13.1 Chapters and sub-chapters There are two steps to cross-reference any heading: Label the heading: # Hello world {#nice-label}. Leave the label off if you like the automated heading generated based on your heading title: for example, # Hello world = # Hello world {#hello-world}. To label an un-numbered heading, use: # Hello world {-#nice-label} or {# Hello world .unnumbered}. Next, reference the labeled heading anywhere in the text using \\@ref(nice-label); for example, please see Chapter 13. If you prefer text as the link instead of a numbered reference use: any text you want can go here. 13.2 Captioned figures and tables Figures and tables with captions can also be cross-referenced from elsewhere in your book using \\@ref(fig:chunk-label) and \\@ref(tab:chunk-label), respectively. See Figure 13.1. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 13.1: Here is a nice figure! Don‚Äôt miss Table 13.1. knitr::kable( head(pressure, 10), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 13.1: Here is a nice table! temperature pressure 0 0.0002 20 0.0012 40 0.0060 60 0.0300 80 0.0900 100 0.2700 120 0.7500 140 1.8500 160 4.2000 180 8.8000 "],["parts.html", "Chapter 14 Parts", " Chapter 14 Parts You can add parts to organize one or more book chapters together. Parts can be inserted at the top of an .Rmd file, before the first-level chapter heading in that same file. Add a numbered part: # (PART) Act one {-} (followed by # A chapter) Add an unnumbered part: # (PART\\*) Act one {-} (followed by # A chapter) Add an appendix as a special kind of un-numbered part: # (APPENDIX) Other stuff {-} (followed by # A chapter). Chapters in an appendix are prepended with letters instead of numbers. "],["footnotes-and-citations.html", "Chapter 15 Footnotes and citations 15.1 Footnotes 15.2 Citations", " Chapter 15 Footnotes and citations 15.1 Footnotes Footnotes are put inside the square brackets after a caret ^[]. Like this one 1. 15.2 Citations Reference items in your bibliography file(s) using @key. For example, we are using the bookdown package (Xie 2024) (check out the last code chunk in index.Rmd to see how this citation key was added) in this sample book, which was built on top of R Markdown and knitr (Xie 2015) (this citation was added manually in an external file book.bib). Note that the .bib files need to be listed in the index.Rmd with the YAML bibliography key. The RStudio Visual Markdown Editor can also make it easier to insert citations: https://rstudio.github.io/visual-markdown-editing/#/citations References Xie, Yihui. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.org/knitr/. ‚Äî‚Äî‚Äî. 2024. Bookdown: Authoring Books and Technical Documents with r Markdown. https://github.com/rstudio/bookdown. This is a footnote.‚Ü©Ô∏é "],["blocks.html", "Chapter 16 Blocks 16.1 Equations 16.2 Theorems and proofs 16.3 Callout blocks", " Chapter 16 Blocks 16.1 Equations Here is an equation. \\[\\begin{equation} f\\left(k\\right) = \\binom{n}{k} p^k\\left(1-p\\right)^{n-k} \\tag{16.1} \\end{equation}\\] You may refer to using \\@ref(eq:binom), like see Equation (16.1). 16.2 Theorems and proofs Labeled theorems can be referenced in text using \\@ref(thm:tri), for example, check out this smart theorem 16.1. Theorem 16.1 For a right triangle, if \\(c\\) denotes the length of the hypotenuse and \\(a\\) and \\(b\\) denote the lengths of the other two sides, we have \\[a^2 + b^2 = c^2\\] Read more here https://bookdown.org/yihui/bookdown/markdown-extensions-by-bookdown.html. 16.3 Callout blocks The R Markdown Cookbook provides more help on how to use custom blocks to design your own callouts: https://bookdown.org/yihui/rmarkdown-cookbook/custom-blocks.html "],["sharing-your-book.html", "Chapter 17 Sharing your book 17.1 Publishing 17.2 404 pages 17.3 Metadata for sharing", " Chapter 17 Sharing your book 17.1 Publishing HTML books can be published online, see: https://bookdown.org/yihui/bookdown/publishing.html 17.2 404 pages By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If you‚Äôd like to customize your 404 page instead of using the default, you may add either a _404.Rmd or _404.md file to your project root and use code and/or Markdown syntax. 17.3 Metadata for sharing Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the index.Rmd YAML. To setup, set the url for your book and the path to your cover-image file. Your book‚Äôs title and description are also used. This gitbook uses the same social sharing data across all chapters in your book- all links shared will look the same. Specify your book‚Äôs source repository on GitHub using the edit key under the configuration options in the _output.yml file, which allows users to suggest an edit by linking to a chapter‚Äôs source file. Read more about the features of this output format here: https://pkgs.rstudio.com/bookdown/reference/gitbook.html Or use: ?bookdown::gitbook "],["references.html", "References", " References Xie, Yihui. 2015. Dynamic Documents with R and Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.org/knitr/. ‚Äî‚Äî‚Äî. 2024. Bookdown: Authoring Books and Technical Documents with r Markdown. https://github.com/rstudio/bookdown. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
